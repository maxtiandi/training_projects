# Прогнозирование оттока клиентов банка
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.

---

**Цель исследования:** Построить модель, которая будет способна спрогнозировать уход клиент из банка в ближайшее время. 

**Контекст исследования:** Исторические данные о поведении клиентов и расторжении договоров с банком.

**Источник данных:** [Данные о поведении клиентов с Kaggle](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)

**Задачи исследования:** 
- Построить модель с предельно большим значением *F1*-меры
- Довести метрику *F1*-меры до 0.59 
- Проверить *F1*-меру на тестовой выборке
- Дополнительно измерять *AUC-ROC*, сравнивать значение этой метрики с *F1*-мерой

**План исследования:**
- Загрузите и подготовьте данные
- Исследовать баланс классов, обучить модель без учёта дисбаланса
- Улучшить качество модели, учитывая дисбаланс классов. Обучить разные модели и найти лучшую
- Провести финальное тестирование.

**Описание данных:**

*Датасэт -  `/datasets/Churn.csv`*

*Признаки:*
- `RowNumber` — индекс строки в данных
- `CustomerId` — уникальный идентификатор клиента
- `Surname` — фамилия
- `CreditScore` — кредитный рейтинг
- `Geography` — страна проживания
- `Gender` — пол
- `Age` — возраст
- `Tenure` — сколько лет человек является клиентом банка
- `Balance` — баланс на счёте
- `NumOfProducts` — количество продуктов банка, используемых клиентом
- `HasCrCard` — наличие кредитной карты
- `IsActiveMember` — активность клиента
- `EstimatedSalary` — предполагаемая зарплата

*Целевой признак:*
- `Exited` — факт ухода клиента

---

# Вывод
**По результатам исследования мы обучили максимально вероятно точную модель, которая способна спрогнозировать уход клиента из банка в ближайшее время**
- Модель -> `RandomForestClassifier(max_depth=9, n_estimators=30, random_state=12345)`
- Значение F1-меры -> `0.647739221871714`
- Значение метрики AUC-ROC ->  `0.8744626933688047`

---

*Исследование было разделено на несколько этапов:*

**1. Подготовка данных:**
- *Изучили общую информацию о данных и выявили решения:*
    - Всего в таблице представлены данные о 10000 клиентах
    - Присутствуют пропуски в столбце `Tenure` 
    - Предложили убрать столбцы `RowNumber`, `CustomerId` и `Surname`
    
    
- *Предобработали данные:*
    - Избавились от "лишних" столбцов
    - Заменили пропуски в столбце `Tenure` на медианное значение по столбцу
    
    
- *Подготовили данные для обучения моделей:*
    - Применили метод `one-hot-encoding` для кодирования количественных переменных
    - Применили стандартизацию через `StandardScaler`
    - Разбили данные на три выборки: обучающую, валидационную и тестовую *(в соотношении 3:1:1)*
    

**2. Исследование задачи:**
- *Исследовали баланс классов -> обнаружили дисбаланс*
    - Класс 0 встречается почти в **4 раза чаще класса 1**
    - Оставшихся пользователей - **79.6%**, ушедших пользователей - **20.4%**
    
    
- *Обучили две модели без учета дисбаланса и изучили их поведение:*

        
- Подобрали оптимальные гиперпараметры для модели `RandomForestClassifier`, обучая модель на несбалансированной выборке: `max_depth=19, n_estimators=40`
- Максимальное полученное значение **f1-меры** для `RandomForestClassifier` на несбалансированной выборке: `0.5657492354740061`
- Максимально полученное значение **f1-меры** для `LogisticRegression` на несбалансированной выборке: `0.2932330827067669`
- Значение метрики **AUC-ROC** для `RandomForestClassifier` на несбалансированной выборке: `0.8405107727141625`
- Значение метрики **AUC-ROC** для `LogisticRegression` на несбалансированной выборке: `0.7505240217104624`
- Модель "Случайного леса" показала значение метрики f1-меры намного выше, нежели у "Логистической регрессии"


**3. Борьба с дисбалансом:**

- *Применили метод **`Upsampling`** для увеличения "отстающей" части выборки:*
        
    - Значение метрик **AUC-ROC** на увеличенной выборке: 
        - *RandomForestClassifier* -> `0.85316132773759897`
        - *LogisticRegression* -> `0.7541671100993135`
    - Значение **F1-меры** на увеличенной выборке:
        - *RandomForestClassifier* -> `0.6114101184068892`
        - *LogisticRegression* -> `0.47822374039282667`
    
    

- *Применили метод **`Downsampling`** для уменьшения "доминирующей" части выборки:*

    - Значение метрик **AUC-ROC** на уменьшенной выборке: 
        - *RandomForestClassifier* -> `0.8449042262601585`
        - *LogisticRegression* -> `0.7521064978692098`
    - Значение **F1-меры** на уменьшенной выборке:
        - *RandomForestClassifier* -> `0.5964585274930102`
        - *LogisticRegression* -> `0.47822374039282667`
    
---
    

- *По итогу перебора моделей с их обучением после использования разных методов по борьбе с дисбалансом, лучше всего себя показала следующая модель со следующими показателями*:

    - Примененный метод: `upsampling`
    - Переменная лучшей модели: `best_model_upsamp`
    - Лучшие гиперпараметры для модели: `RandomForestClassifier(max_depth=9, n_estimators=30, random_state=12345)`
    - **F1-мера** на увеличенной выборке: `0.6114101184068892`
    - **AUC-ROC** на увеличенной выборке: `0.8531613277375989`

---

**4. Тестирование модели:**
- Протестировав нашу модель, мы определили значение метрики **F1** = `0.6261980830670926`. 
    - Значение метрики **AUC-ROC** при этом составило `0.8714782552468223`


- Объединив обучающую и валидационные выборки вместе, обучили на новой "большой" выборке нашу модель в заключительный раз


- Протестировав новообученную модель еще подняли значение **F1-меры** до предела (в данном контексте исследования) - `0.647739221871714`. 
    - Значение **AUC-ROC** стало равно `0.8744626933688047`
